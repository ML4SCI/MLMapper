{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#expand cell width to 100%\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Unmixing_Autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None, 421, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " 1st_Conv_layer (Conv1D)        (None, 139, 32)      192         ['input_layer[0][0]']            \n",
      "                                                                                                  \n",
      " 1st_Activation (Activation)    (None, 139, 32)      0           ['1st_Conv_layer[0][0]']         \n",
      "                                                                                                  \n",
      " 1st_Batch_Norm (BatchNormaliza  (None, 139, 32)     128         ['1st_Activation[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " 1st_Dropout (Dropout)          (None, 139, 32)      0           ['1st_Batch_Norm[0][0]']         \n",
      "                                                                                                  \n",
      " 2nd_Conv_layer (Conv1D)        (None, 45, 16)       2576        ['1st_Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " 2nd_Activation (Activation)    (None, 45, 16)       0           ['2nd_Conv_layer[0][0]']         \n",
      "                                                                                                  \n",
      " 2nd_Batch_Norm (BatchNormaliza  (None, 45, 16)      64          ['2nd_Activation[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " 2nd_Dropout (Dropout)          (None, 45, 16)       0           ['2nd_Batch_Norm[0][0]']         \n",
      "                                                                                                  \n",
      " 3rd_Conv_layer (Conv1D)        (None, 14, 16)       1296        ['2nd_Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " 3rd_Activation (Activation)    (None, 14, 16)       0           ['3rd_Conv_layer[0][0]']         \n",
      "                                                                                                  \n",
      " 3rd_Batch_Norm (BatchNormaliza  (None, 14, 16)      64          ['3rd_Activation[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " 3rd_Dropout (Dropout)          (None, 14, 16)       0           ['3rd_Batch_Norm[0][0]']         \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 224)          0           ['3rd_Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " 1st_Fully_Connected_Layer (Den  (None, 112)         25200       ['flatten[0][0]']                \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " 7_Element_Abundance_Embedding   (None, 7)           791         ['1st_Fully_Connected_Layer[0][0]\n",
      " (Dense)                                                         ']                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 7)            0           ['7_Element_Abundance_Embedding[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " kAbundanceEstimator (Functiona  (None, 1)           3937        ['input_layer[0][0]']            \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " uAbundanceEstimator (Functiona  (None, 1)           3937        ['input_layer[0][0]']            \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " thAbundanceEstimator (Function  (None, 1)           3937        ['input_layer[0][0]']            \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 10)           0           ['kAbundanceEstimator[0][0]',    \n",
      "                                                                  'uAbundanceEstimator[0][0]',    \n",
      "                                                                  'thAbundanceEstimator[0][0]',   \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " 1st_Fully_Connected_Layer_Deco  (None, 112)         1232        ['concatenate[0][0]']            \n",
      " der (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 112, 1)       0           ['1st_Fully_Connected_Layer_Decod\n",
      "                                                                 er[0][0]']                       \n",
      "                                                                                                  \n",
      " 1st_Trans_Conv_Layer (Conv1DTr  (None, 116, 16)     96          ['tf.expand_dims[0][0]']         \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " 1st_Decoder_Activation (Activa  (None, 116, 16)     0           ['1st_Trans_Conv_Layer[0][0]']   \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " 1st_Decoder_Batch_Norm (BatchN  (None, 116, 16)     64          ['1st_Decoder_Activation[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " 1st_Decoder_Dropout (Dropout)  (None, 116, 16)      0           ['1st_Decoder_Batch_Norm[0][0]'] \n",
      "                                                                                                  \n",
      " 2nd_Trans_Conv_Layer (Conv1DTr  (None, 120, 16)     1296        ['1st_Decoder_Dropout[0][0]']    \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " 2nd_Decoder_Activation (Activa  (None, 120, 16)     0           ['2nd_Trans_Conv_Layer[0][0]']   \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " 2nd_Decoder_Batch_Norm (BatchN  (None, 120, 16)     64          ['2nd_Decoder_Activation[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " 2nd_Decoder_Dropout (Dropout)  (None, 120, 16)      0           ['2nd_Decoder_Batch_Norm[0][0]'] \n",
      "                                                                                                  \n",
      " 3rd_Trans_Conv_Layer (Conv1DTr  (None, 124, 16)     1296        ['2nd_Decoder_Dropout[0][0]']    \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " 3rd_Decoder_Activation (Activa  (None, 124, 16)     0           ['3rd_Trans_Conv_Layer[0][0]']   \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " 3rd_Decoder_Batch_Norm (BatchN  (None, 124, 16)     64          ['3rd_Decoder_Activation[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " 3rd_Decoder_Dropout (Dropout)  (None, 124, 16)      0           ['3rd_Decoder_Batch_Norm[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 1984)         0           ['3rd_Decoder_Dropout[0][0]']    \n",
      "                                                                                                  \n",
      " 2nd_Fully_Connected_Layer_Deco  (None, 2048)        4065280     ['flatten_1[0][0]']              \n",
      " der (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " 3rd_Fully_Connected_Layer_Deco  (None, 421)         862629      ['2nd_Fully_Connected_Layer_Decod\n",
      " der (Dense)                                                     er[0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,974,143\n",
      "Trainable params: 4,962,108\n",
      "Non-trainable params: 12,035\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def refactor_block_name(num_):\n",
    "    if num_ == 1:\n",
    "        return f\"{num_}st\"\n",
    "    elif num_ ==2 :\n",
    "        return f\"{num_}nd\"\n",
    "    elif num_ == 3:\n",
    "        return f\"{num_}rd\"\n",
    "    else:\n",
    "        return f\"{num_}th\"\n",
    "\n",
    "def estimateAbundances(inputNodes):\n",
    "    sampleWiseSums=tf.keras.backend.sum(inputNodes,\n",
    "                                     axis=1,keepdims=True)\n",
    "    return inputNodes/sampleWiseSums\n",
    "\n",
    "def pearson_correlation(x,y):\n",
    "    x_mean=tf.reduce_mean(x)\n",
    "    y_mean=tf.reduce_mean(y)\n",
    "    x_diff=x-x_mean\n",
    "    y_diff=y-y_mean\n",
    "    covariance=tf.reduce_mean(tf.multiply(x_diff,y_diff))\n",
    "    x_std=tf.sqrt(tf.reduce_mean(tf.square(x_diff)))\n",
    "    y_std=tf.sqrt(tf.reduce_mean(tf.square(y_diff)))\n",
    "    correlation=covariance/(x_std*y_std)\n",
    "    return correlation\n",
    "\n",
    "def load_abundance_models(inputLayer, trainable = False, mineral_list = [\"K\", \"U\", \"Th\"],\n",
    "                            base_dirs = \"/Users/msd/Desktop/coderepo/sandeepan/Ml4Sci_GRS_abundance_estimation-Multi_Task_Models\"):\n",
    "    vars = locals()\n",
    "    mineral_model_list = []\n",
    "    for mineral_ in mineral_list:\n",
    "        var_name = f\"{mineral_.lower()}AbundanceEstimator\"\n",
    "        vars[var_name] = tf.keras.models.load_model(f\"{base_dirs}/Models/untrained_{mineral_}_Abundance_Model.h5\",\n",
    "                                               custom_objects={'pearson_correlation':pearson_correlation},\n",
    "                                               compile=True)\n",
    "        vars[var_name]._name = var_name ## check the name of all the model as it seems two model share the same name\n",
    "        if trainable == False:\n",
    "            vars[var_name].trainable = False\n",
    "        mineral_model_list.append(vars[var_name](inputLayer))\n",
    "\n",
    "    return mineral_model_list\n",
    "\n",
    "def create_convolution_blocks(inputs, num_filters, num_block, global_seed = 23):\n",
    "    block_name = refactor_block_name(num_block)\n",
    "    convolutionLayer = tf.keras.layers.Conv1D(filters=num_filters,kernel_size=5,strides=3,\n",
    "                                                padding='valid',name=f\"{block_name}_Conv_layer\")(inputs)\n",
    "    reluActivation = tf.keras.layers.Activation('relu',name=f\"{block_name}_Activation\")(convolutionLayer)\n",
    "    batchNormalization=tf.keras.layers.BatchNormalization(name=f\"{block_name}_Batch_Norm\")(reluActivation)\n",
    "    dropoutLayer=tf.keras.layers.Dropout(0.5, noise_shape=None,seed=global_seed,name=f\"{block_name}_Dropout\")(batchNormalization)\n",
    "    return dropoutLayer\n",
    "\n",
    "def create_transposed_blocks(inputs, num_filters, num_block, global_seed  = 23):\n",
    "    block_name = refactor_block_name(num_block)\n",
    "    transposedConvolutionalLayer=tf.keras.layers.Conv1DTranspose(filters=16,kernel_size=5,strides=1,\n",
    "                                                activation=None,name=f\"{block_name}_Trans_Conv_Layer\")(inputs)\n",
    "    decoderReluActivation=tf.keras.layers.Activation('relu', name=f\"{block_name}_Decoder_Activation\")(transposedConvolutionalLayer)\n",
    "    decoderBatchNormalization=tf.keras.layers.BatchNormalization(name=f\"{block_name}_Decoder_Batch_Norm\")(decoderReluActivation)\n",
    "    decoderDropoutLayer=tf.keras.layers.Dropout(0.5,noise_shape=None,seed=global_seed, name=f\"{block_name}_Decoder_Dropout\")(decoderBatchNormalization)\n",
    "    return decoderDropoutLayer\n",
    "\n",
    "def create_unmixing_autoencoder(input_shape):\n",
    "    inputLayer=tf.keras.Input(shape=input_shape, name= \"input_layer\")\n",
    "\n",
    "    firstConvBlock = create_convolution_blocks(inputLayer, 32, 1)\n",
    "    secondConvBlock = create_convolution_blocks(firstConvBlock, 16, 2)\n",
    "    thirdConvBlock = create_convolution_blocks(secondConvBlock, 16, 3)\n",
    "\n",
    "    flattenedFeatures=tf.keras.layers.Flatten()(thirdConvBlock)\n",
    "    firstFullyConnectedLayer=tf.keras.layers.Dense(112,activation='relu',name=\"1st_Fully_Connected_Layer\")(flattenedFeatures)\n",
    "    secondFullyConnectedLayer=tf.keras.layers.Dense(7,activation='relu', name=\"7_Element_Abundance_Embedding\")(firstFullyConnectedLayer)\n",
    "\n",
    "    abundanceEmbedding=tf.keras.layers.Lambda(estimateAbundances)(secondFullyConnectedLayer)\n",
    "    abundance_mineral_list = load_abundance_models(inputLayer, False)\n",
    "\n",
    "    allAbundanceValues=tf.keras.layers.concatenate([*abundance_mineral_list, abundanceEmbedding], axis=-1)\n",
    "\n",
    "    firstFullyConnectedLayerDecoder=tf.keras.layers.Dense(112,activation='relu',name=\"1st_Fully_Connected_Layer_Decoder\")(allAbundanceValues)\n",
    "    firstFullyConnectedLayerDecoder = tf.expand_dims(firstFullyConnectedLayerDecoder,axis=-1)\n",
    "\n",
    "    firstTransConvBlock = create_transposed_blocks(firstFullyConnectedLayerDecoder, 16, 1)\n",
    "    secondTransConvBlock = create_transposed_blocks(firstTransConvBlock, 16, 2)\n",
    "    thirdTransConvBlock = create_transposed_blocks(secondTransConvBlock, 32, 3)\n",
    "\n",
    "    decoderFlattenedFeatures = tf.keras.layers.Flatten()(thirdTransConvBlock)\n",
    "    secondFullyConnectedLayerDecoder=tf.keras.layers.Dense(2048,activation='relu',name=\"2nd_Fully_Connected_Layer_Decoder\")(decoderFlattenedFeatures)\n",
    "    thirdFullyConnectedLayerDecoder=tf.keras.layers.Dense(noOfChannels,activation='relu',name=\"3rd_Fully_Connected_Layer_Decoder\")(secondFullyConnectedLayerDecoder)\n",
    "\n",
    "    kAbundanceEstimator=tf.keras.Model(inputs=inputLayer,\n",
    "                                   outputs=[abundanceEmbedding,thirdFullyConnectedLayerDecoder],name=\"Unmixing_Autoencoder\")\n",
    "    \n",
    "    embeddingLossFunction=tf.keras.losses.MeanSquaredError()\n",
    "    decoderLossFunction=tf.keras.losses.CosineSimilarity()\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "    kAbundanceEstimator.compile(optimizer= optimizer, loss = [embeddingLossFunction, decoderLossFunction], metrics = ['accuracy', 'mse'])\n",
    "\n",
    "    return kAbundanceEstimator\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import gc\n",
    "K.clear_session()\n",
    "\n",
    "noOfChannels = 421\n",
    "\n",
    "unmixing_autoencoder = create_unmixing_autoencoder((noOfChannels, 1))\n",
    "print(unmixing_autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e77a2152aab457a436ea9c48d519942da0545fa5fe7addf6d99b15f5b48cc8f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
